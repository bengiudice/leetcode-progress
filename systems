1 foundations
 client-server
 networking

2 key-characteristics
 availability
 redundancy
 throughput
 latency
 consistency (up-to-date-ness stale?)

3 components
 load-balancer
 caching
 proxies
 rate-limiting
 redirection

4 tech
 real
 nginx
 zookeeper
 xcd
 redis
 amazon s3
 google cloud storage

client-server
 server listens
 client requests

ports
 dns 53 http 80 https 443 ssh 22
 2^16 65535 ports

network protocols
 IP (2^16B 65535B 0.66MB)
  header (20-60B): srcip destip size vers
  data (): TCP
            header ():
	    data ():
 TCP
  handshake
  timeout
  delivery
  close-out
  implemented via IP
 HTTP
  request response
  implemented via TCP
  methods, endpoints

storage
 databases
  store & retrieve data
  server
  persistence
   disk
   memory
    hashtable array etc
    fast

latency & throughput
 2 most important perforance measures
 not neceserily collelated
 latency 
  (time it takes for data to traverse system)
  1MB read seq RAM       250 us    0.25 ms
  1MB read ssd         1 000 us    1    ms
  1MB 1Gbps network   10 000 us   10    ms
  1MB HDD             20 000 us   20    ms
  1pkt ICRT          150 000 us  150    ms
 throughput
  (work machine can perform or support in given time)
  operations system can handle per time unit
  requests per second RPS
  queries  per second QPS
  bottleneck, fit-through
  pay more -> increase throughput
  Gbps Mbps Kbps bps

availability
 resistance to failures
 fault-tolerance
 percentage of a systems uptime in a given year
 nines
  55.5555555 nine  fives 162.33 days 
  90         one   nine
  95         one and a half nines
  99         two   nines
  99.9       three nines
  99.99      four  nines
  99.999     five  nines
  99.9999999 nine  nines
  five nines is the gold standard (5.26 min)
 service level agreement SLA 
  SLA is made up of objectives SLOs
 HA high availability
  5 nines or more
 tradeoffs (may increase latency and lower throughput)
 what subsystems require HA
 eliminate single points of failure via redundancy
  may require (multiple) load balancers
  pasive redundancy
   adding extra servers
   aeroplane engines
  active redundancy
   swarm which reacts to single failures
   warm servers?
   reconfigure
   leader election?
 rigourous process in place to handle and react to failures
 
caching
 important!
 reduce or improve the latency
 storing data in different location such that it's faster to access
 client level
 server level
 hardware level
 in-between (server-database or client-server) level
 network request or computationally long operation or avoid too many reads
 write cache
  write through
   overwrite cace -> then overwrite database
   downside it still requires a database transaction
 write back
  overwrite cache, leave database as old. 
  asynchronously update the database with the cache
  could be on intervals or event or full (eviction)
  could lose data as cache likely in memory
 cache invalidation / stale ?
  single cache or single source of truth
  do we care about the accuracy of the data?
 static is good for cache
 mutable data is tricky
 single entity read/write to data is good for cache
 dont care about consistency / staleness then good for cache
 eviction policies
  LRU (least recently used)
  LFU (least frequently used)
  LIFO
  FIFO
  Random
 CDN content delivery network
  PoPs points of presence
  lowers latency for particular regions
  Cloudflare, Google Cloud CDN

proxy
 forward (default)
  server between clients (or set of) and server (or set of)
  on the clients team
  acts on the client's behalf
  middle-man
  server thinks it is interacting with a client
 reverse
  I am the server now ;) 
  acts on behalf of the server
  client thinks it is interacting with the server
  useful!
  filter, logging, cache, load balancer
  nginx webserver reverse-proxy load-balancer

load balancer
 facilitates horizontal scaling
 clients -- load balancer -- servers
 increases throughput, lower latency, better use of resources
 type of reverse proxy
 useful for dns, database, webserver
 types
  hardware / software
  do more / customise / scaling with software
 register / deregister servers with load-balancer
 redirection / distribution / server selection strategies
  random
  round-robin
  weighted round-robin
  performance / load (health checks: lowest load, response time, traffic )
  ip (hash ip then redirect, good for caching)
  path (functionality)
 redundant load balancers
 plan to avoid hot spots

hashing
 hash the request and distribute via loadbalancer
 mod #servers
 data -> fixed size (int) value
 algorithms
  consistent
   circle, hash serverIDs, hash clientIDs, move clockwise, first server = handler
   add or remove server = maintain most of the client-server mappings
   maintains some level of consistency of clients and servers
   hash serverIDs multiple ways = place them multiple times on circle
   weight by placing (hashing multiple) one server multiple times
  rendezvous
   rank servers per client
   highest random weight
   minimises remapping
 md5 sha3 ... 
 uniformity!
 adding a server, or a server fails
  change mod value
  however redistributes and = cache misses. 
  bad
  solution consistent rendezvous

database
 server. disk/memory. record/query data. long lived
 interact via network protocols

relational databases
 structured
 schema
 normalised
 tables (relations) -> represent an entity
 rows represent instances of an entity (records)
 cols represent atributes of an entity instance
 rows, cols, datatypes
 rigourous, well defined
 most support SQL 
  perform queries directly on the database, dont have to load the data first
 SQL database
 postgresql
 powerful querying
 ACID transaction
  atomicity (sub-operations as a block. All fail/succeed. no inbetween.)
  consistency (strong) (follow rules, no stale state, no invalid state)
  isolation (multiple parallel transactions same effect as serial)
  durability (saved, persist over crash/powerloss)
 index
  complex!
  aux datastructre optimised for searching on a particular column
  more space use, write operations slower
 important!
 eventual consistency
  reads may be stale, eventually correct

non-relational databases
 semi-structured
 custom query language
 
key-value store
 database
 key-strings or sometimes other
 hashtable
 caching, dynamic configuration
 some persist to disk
 dynamoDB
 etcd (strongly consistent, HA, leader-election)
 redis (in-memory, fast best effort caching, rate limiting)
  expiry time
 zookeeper (strongly consistent, HA, important conf, leader-election)
 simple, fast lookups
 strong/eventual consistency

specialised sotrage
 blob-store
  arbitary piece of unstructured data
  optimised for massive unstructured data
  behave like key-value pairs
  key
  large binaries, database snapshots, images, static assets
  google-cloud-storage s3 azure-blob
 time-seriesdb
  time-series data
  data points occurr at a moment in time
  rolling average / local maxima/minima
  monitoring telemetry stock-prices crypto-prices
  iot events streams
  influxDB
  graphite
  prometheus
 graphdb
  relationship is first-class
  deeply connected
  multiple levels of relationships
  social-networks
  links
  neo4j (cypher is sql for graphs)
 spatialdb
  geometric space
  locations
  spacial index
  r-tree kd-tree n-tree
  quadtree
   grid
   0 or 4 children
   subdivide into quadrants if there are still more than k elements
   log4(n)
 pagination (dont return all results, just first k)
 may get away with out of the box optimisations for some of the more general dbs
  ask interviewer

replication and sharding
 systems performance is often only as good as the DBs
 redundancy, partitioning
 replica duplicate standby db
  takes over when main db fails
  write to main db, sync write to replica
  cannot be out of date
 async replication
  better latency in areas
 multiple database servers?
 replication
  duplicate data form one db server to others
  redundancy, failure tolerance
  move data closer to clients (decrease latency)
 sharding (data partitioning)
  splitting database into two or more pieces
  strategies
   client region, type, hash of column
  increases throughput, reduce storage
  shard based on rows
  need balanced distribution
  avoid hotspots
  use hashing function
   potentially consistent
   but doesn't protect from failure
  partitioning logic in reverse proxy
 multiple databases vs one db with sharding?

leader election
 advanced
 action you don't want to perform multiple times
 leader is only one that acts
 followers standby
 distributed consensus is difficult
 consensus algorithms
  math heavy
  multiple nodes in cluster to agree on a data value
  paxos raft
  complicated
  zookeper etcd (happen to allow you to implement leader election)
  etcd
   key-value store
   highly available
   strongly consistent (guaranteed to return the same values)
   raft consensus algorithm
   use etcd key:leader val:serverID to implement leader election

peer-to-peer networks
 advanced
 good for high throughput data transfer
 peer discovery
 peer selection
 central orchistrator / tracker
 gossip / epidemic protocol
  mapping of chunk to ip address hashtable which they share when communicating
  distributed hash table DHT
 chunks are numbered
 kraken from uber

