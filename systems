1 foundations
 client-server
 networking

2 key-characteristics
 availability
 redundancy
 throughput
 latency
 consistency (up-to-date-ness stale?)

3 components
 load-balancer
 caching
 proxies
 rate-limiting
 redirection

4 tech
 real
 nginx
 zookeeper
 xcd
 redis
 amazon s3
 google cloud storage

client-server
 server listens
 client requests

ports
 dns 53 http 80 https 443 ssh 22
 2^16 65535 ports

network protocols
 IP (2^16B 65535B 0.66MB)
  header (20-60B): srcip destip size vers
  data (): TCP
            header ():
	    data ():
 TCP
  handshake
  timeout
  delivery
  close-out
  implemented via IP
 HTTP
  request response
  implemented via TCP
  methods, endpoints

storage
 databases
  store & retrieve data
  server
  persistence
   disk
   memory
    hashtable array etc
    fast

latency & throughput
 2 most important perforance measures
 not neceserily collelated
 latency 
  (time it takes for data to traverse system)
  1MB read seq RAM       250 us    0.25 ms
  1MB read ssd         1 000 us    1    ms
  1MB 1Gbps network   10 000 us   10    ms
  1MB HDD             20 000 us   20    ms
  1pkt ICRT          150 000 us  150    ms
 throughput
  (work machine can perform or support in given time)
  operations system can handle per time unit
  requests per second RPS
  queries  per second QPS
  bottleneck, fit-through
  pay more -> increase throughput
  Gbps Mbps Kbps bps

availability
 resistance to failures
 fault-tolerance
 percentage of a systems uptime in a given year
 nines
  55.5555555 nine  fives 162.33 days 
  90         one   nine
  95         one and a half nines
  99         two   nines
  99.9       three nines
  99.99      four  nines
  99.999     five  nines
  99.9999999 nine  nines
  five nines is the gold standard (5.26 min)
 service level agreement SLA 
  SLA is made up of objectives SLOs
 HA high availability
  5 nines or more
 tradeoffs (may increase latency and lower throughput)
 what subsystems require HA
 eliminate single points of failure via redundancy
  may require (multiple) load balancers
  pasive redundancy
   adding extra servers
   aeroplane engines
  active redundancy
   swarm which reacts to single failures
   warm servers?
   reconfigure
   leader election?
 rigourous process in place to handle and react to failures
 
caching
 important!
 reduce or improve the latency
 storing data in different location such that it's faster to access
 client level
 server level
 hardware level
 in-between (server-database or client-server) level
 network request or computationally long operation or avoid too many reads
 write cache
  write through
   overwrite cace -> then overwrite database
   downside it still requires a database transaction
 write back
  overwrite cache, leave database as old. 
  asynchronously update the database with the cache
  could be on intervals or event or full (eviction)
  could lose data as cache likely in memory
 cache invalidation / stale ?
  single cache or single source of truth
  do we care about the accuracy of the data?
 static is good for cache
 mutable data is tricky
 single entity read/write to data is good for cache
 dont care about consistency / staleness then good for cache
 eviction policies
  LRU (least recently used)
  LFU (least frequently used)
  LIFO
  FIFO
  Random
 CDN content delivery network
  PoPs points of presence
  lowers latency for particular regions
  Cloudflare, Google Cloud CDN

proxy
 forward (default)
  server between clients (or set of) and server (or set of)
  on the clients team
  acts on the client's behalf
  middle-man
  server thinks it is interacting with a client
 reverse
  I am the server now ;) 
  acts on behalf of the server
  client thinks it is interacting with the server
  useful!
  filter, logging, cache, load balancer
  nginx webserver reverse-proxy load-balancer

load balancer
 facilitates horizontal scaling
 clients -- load balancer -- servers
 increases throughput, lower latency, better use of resources
 type of reverse proxy
 useful for dns, database, webserver
 types
  hardware / software
  do more / customise / scaling with software
 register / deregister servers with load-balancer
 redirection / distribution / server selection strategies
  random
  round-robin
  weighted round-robin
  performance / load (health checks: lowest load, response time, traffic )
  ip (hash ip then redirect, good for caching)
  path (functionality)
 redundant load balancers
 plan to avoid hot spots

hashing
 hash the request and distribute via loadbalancer
 mod #servers
 data -> fixed size (int) value
 algorithms
  consistent
   circle, hash serverIDs, hash clientIDs, move clockwise, first server = handler
   add or remove server = maintain most of the client-server mappings
   maintains some level of consistency of clients and servers
   hash serverIDs multiple ways = place them multiple times on circle
   weight by placing (hashing multiple) one server multiple times
  rendezvous
   rank servers per client
   highest random weight
   minimises remapping
 md5 sha3 ... 
 uniformity!
 adding a server, or a server fails
  change mod value
  however redistributes and = cache misses. 
  bad
  solution consistent rendezvous

database
 server. disk/memory. record/query data. long lived
 interact via network protocols

relational databases
 structured
 schema
 normalised
 tables (relations) -> represent an entity
 rows represent instances of an entity (records)
 cols represent atributes of an entity instance
 rows, cols, datatypes
 rigourous, well defined
 most support SQL 
  perform queries directly on the database, dont have to load the data first
 SQL database
 postgresql
 powerful querying
 ACID transaction
  atomicity (sub-operations as a block. All fail/succeed. no inbetween.)
  consistency (strong) (follow rules, no stale state, no invalid state)
  isolation (multiple parallel transactions same effect as serial)
  durability (saved, persist over crash/powerloss)
 index
  complex!
  aux datastructre optimised for searching on a particular column
  more space use, write operations slower
 important!
 eventual consistency
  reads may be stale, eventually correct

non-relational databases
 semi-structured
 custom query language
 
key-value store
 database
 key-strings or sometimes other
 hashtable
 caching, dynamic configuration
 some persist to disk
 dynamoDB
 etcd (strongly consistent, HA, leader-election)
 redis (in-memory, fast best effort caching, rate limiting)
  expiry time
 zookeeper (strongly consistent, HA, important conf, leader-election)
 simple, fast lookups
 strong/eventual consistency

specialised sotrage
 blob-store
  arbitary piece of unstructured data
  optimised for massive unstructured data
  behave like key-value pairs
  key
  large binaries, database snapshots, images, static assets
  google-cloud-storage s3 azure-blob
 time-seriesdb
  time-series data
  data points occurr at a moment in time
  rolling average / local maxima/minima
  monitoring telemetry stock-prices crypto-prices
  iot events streams
  influxDB
  graphite
  prometheus
 graphdb
  relationship is first-class
  deeply connected
  multiple levels of relationships
  social-networks
  links
  neo4j (cypher is sql for graphs)
 spatialdb
  geometric space
  locations
  spacial index
  r-tree kd-tree n-tree
  quadtree
   grid
   0 or 4 children
   subdivide into quadrants if there are still more than k elements
   log4(n)
 pagination (dont return all results, just first k)
 may get away with out of the box optimisations for some of the more general dbs
  ask interviewer

replication and sharding
 systems performance is often only as good as the DBs
 redundancy, partitioning
 replica duplicate standby db
  takes over when main db fails
  write to main db, sync write to replica
  cannot be out of date
 async replication
  better latency in areas
 multiple database servers?
 replication
  duplicate data form one db server to others
  redundancy, failure tolerance
  move data closer to clients (decrease latency)
 sharding (data partitioning)
  splitting database into two or more pieces
  strategies
   client region, type, hash of column
  increases throughput, reduce storage
  shard based on rows
  need balanced distribution
  avoid hotspots
  use hashing function
   potentially consistent
   but doesn't protect from failure
  partitioning logic in reverse proxy
 multiple databases vs one db with sharding?

leader election
 advanced
 action you don't want to perform multiple times
 leader is only one that acts
 followers standby
 distributed consensus is difficult
 consensus algorithms
  math heavy
  multiple nodes in cluster to agree on a data value
  paxos raft
  complicated
  zookeper etcd (happen to allow you to implement leader election)
  etcd
   key-value store
   highly available
   strongly consistent (guaranteed to return the same values)
   raft consensus algorithm
   use etcd key:leader val:serverID to implement leader election

peer-to-peer networks
 advanced
 good for high throughput data transfer
 peer discovery
 peer selection
 central orchistrator / tracker
 gossip / epidemic protocol
  mapping of chunk to ip address hashtable which they share when communicating
  distributed hash table DHT
 chunks are numbered
 kraken from uber

polling and streaming
 polling
  clients request for data from server on set interval
 streaming
  open long lived socket
  clients listen
  server pushes data to client
  pushing
  continuous
  instantaneous
  high frequency

configuration
 set of parameters/constants
 isolated file
 yaml/json
 static 
  (bundled/packaged with codebase)
  safer slower
 dynamic
  separate from application code
  backed by db that your app queries
  quick risk
  tools / review / access controls / deployment systems around cfg
   review process for changes
   deployed at a faster cycle
   
rate limiting
 security performance
 limiting the amount of operations that can be performed in a given time
 users, ip, region, entire system
 can fall apart in distributed systems
  unless very reliable consistent load balancing
  solution
   distributed database of rate-limiting info e.g redis
 tier based rate limiting?

logging, monitoring and alerting
 collect and store in db
 syslog, json format
 meaningful metrics
 fails /wk
 logins /wk
 systems in place to monitor
 can scrape logs to generate metrics out of them
 time-series db
  serves periodically send metrics to this db
  graphana to create graphs
 hook monitoring system into slack
 alerting system

publish/subscribe pubsub pattern 
 publisher subscriber topic messsages
 topics contain a persistent database of messages
 guaranteed at least once delivery
 publishers publish to topics
 susbsribers subscribe to topics
 subscribers send ack to topics on recipt of message
 idempotent operation
  multiple operations have same effect as one
  often messages need to be idempotent
 topic are a queue
 message ordering
 replay
 different topics for
  different data
  regions
  users etc
  separation of concerns
  can add filtering/features to individual topics
 kafka google cloud pubsub
 end-to-end encription

map reduce
 distributed filesystem with central control plane
 map data to k/v pairs then reduce
 send the map functions to the data so they run locally (dont move the data)
 map and reduce functions must be idempotent
  they may fail and control plane will retry
 reorganise kv pairs and reduce by worker nodes
 shuffle/reorganise kv pair
 shuffle step pairs of the same key are routed to the same worker node
 distributed file system
  abstraction over a large cluster of machines
  act as one large file system
  Google file system GFS
  hadoop distributed file system hdfs
  files split into chunks and chunks are sharded accross cluster
  central control plane decides where chunks reside, routing reads and coms
  extremely large scale persistent storage
  hadoop supports mapreduce
   over hdfs

security
 symmectric encryption
  1 key, aes (advanced encription standard)
  1 key encripts and decripts data
  shared key
  fast
 asymmectric encryption
  public key
  private key
  pair of keys mathematically bound
  anyone can encrypt data with public key
  only the holder of the private key can decrypt data
  slower
 https
  runs on tls transport-layer-security
   ssl was the predecesor (secure sockets layer)
    certificate
   handshake
  first asymetric key handshake then symetric sesion key

API design
 "design the twitter API"
 what part? who consuming? 
 swagger
  interface description language IDL
  format to describe apis
 vs plaintext
 access control list acl
 pagination
 crud cread read update delete
 json yaml
 10mins gather requirements

clarify
 10mins at start
 what functionality? can be very detailed
 what scale? how many users? global userbase? regional userbase?
  how much data can a user upload etc?
 latency? availability? consistency? throughput?

planning
 write a plan for design
 1 or 2 minutes
 bullet points or numbered steps
 after requirements
  A storage 1,2
  B functionality 1,2,3
  A buyer
  B seller

estimation
 do it
 mem < ssd < network < hdd < net-continental-round-trip
 1 MB RAM                         100     us
 1 MB SSD                           1     ms
 1 MB network                      10     ms
 1 MB HDD                          10     ms
 inter-continental round trip     100     ms
 char                               1      B
 brief metadata (name, desc, attr)  1     KB
 image high-q 1920-1080             1     MB
 image lossy-compressed            10      x
 20 mins HD video                   1     GB
 server storage                    10     TB
 server memory                      1     TB
 http request intra-c             100     ms
 http request cross-c round         1      s
 4G smartphone                      1   MB/s
 public internet (home wifi)       10   MB/s
 within data centre                 1   GB/s

communication
 justify each decision
 think out loud
 confirm approach with interviewer regularly
 
diagramming
 write approach / requirements notes at left
 make sure you have space
 use color / consistent symbols
 label all nodes / edges

other
 CAP theorem
  consistency, availability, partition tolerance
  distributed system can only achieve 2/3
  almost all useful systems have network partition tolerance so
   = consistency, availability. pick one. 
 database lock
  ACID will cause updating rows to lock
  block
  atomicity
 hot spot
  hashing function or sharding key are sub-optimal
 microservice architecture
  many small web services compiled and deployed independently
  counterpart of monoliths
  split monolith once it reaches a very large size
 pagination
  large response from network request API returns only a single page
  plus an identifier or token for the client to request the next page
  list api endpoints
 peer-to-peer network
  divide workload between themselves
 percentiles
  latency distribution
  Xth percentile is 100ms
  X% of the requests have latencies of 100ms or less
  may be in a SLA
 process
  program that is currently running
  always assume process may get terminated at any time
 sharding
  data partitioning
  split database into shards
  increase throughput
  region type column-hash
 socket
  file which represents a TCP connection.
  process can read/write to file to act as a sream
 stateful
  functionality from storing / retrieving from disk
  databases
  difficult to manage
  cant be stopped and restarted on any machine
 stateless
  does not require state to be persisted to disk
  can hold some state i.e caching layers
  can run process same way on any machine and move it around
 worker pool pattern
  pool of workers take tasks off a single shared queue
  process independently
  each task at least once
  to handle network partitions workers must confirm status of task after completion
   success / failure
 task queue pattern
